{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 188 - Project Proposal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Description\n",
    "\n",
    "You have the choice of doing either (1) an AI solve a problem style project or (2) run a Special Topics class on a topic of your choice.  If you want to do (2) you should fill out the _other_ proposal for that. This is the proposal description for (1).\n",
    "\n",
    "You will design and execute a machine learning project. There are a few constraints on the nature of the allowed project. \n",
    "- The problem addressed will not be a \"toy problem\" or \"common training students problem\" like 8-Queens or a small Traveling Salesman Problem or similar\n",
    "- If its the kind of problem (e.g., RL) that interacts with a simulator or live task, then the problem will have a reasonably complex action space. For instance, a wupus world kind of thing with a 9x9 grid is definitely too small.  A simulated mountain car with a less complex 2-d road and simplified dynamics seems like a fairly low achievement level.  A more complex 3-d mountain car simulation with large extent and realistic dynamics, sure sounds great!\n",
    "- If its the kind of problem that uses a dataset, then the dataset will have >1k observations and >5 variables. I'd prefer more like >10k observations and >10 variables. A general rule is that if you have >100x more observations than variables, your solution will likely generalize a lot better. The goal of training an unsupervised machine learning model is to learn the underlying pattern in a dataset in order to generalize well to unseen data, so choosing a large dataset is very important.\n",
    "- The project must include some elements we talked about in the course\n",
    "- The project will include a model selection and/or feature selection component where you will be looking for the best setup to maximize the performance of your AI system. Generally RL tasks may require a huge amount of training, so extensive grid search is unlikely to be possible. However expoloring a few reasonable hyper-parameters may still be possible. \n",
    "- You will evaluate the performance of your AI system using more than one appropriate metric\n",
    "- You will be writing a report describing and discussing these accomplishments\n",
    "\n",
    "\n",
    "Feel free to delete this description section when you hand in your proposal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Katie Chung\n",
    "- Jiawei Gao\n",
    "- Grace Ortiz\n",
    "- Hsiang-An Pao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract - Jiawei\n",
    "This section should be short and clearly stated. It should be a single paragraph <200 words.  It should summarize: \n",
    "- what your goal/problem is\n",
    "- what the data used represents and how they are measured\n",
    "- what you will be doing with the data\n",
    "- how performance/success will be measured"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background - Jiawei\n",
    "\n",
    "Fill in the background and discuss the kind of prior work that has gone on in this research area here. **Use inline citation** to specify which references support which statements.  You can do that through HTML footnotes (demonstrated here). I used to reccommend Markdown footnotes (google is your friend) because they are simpler but recently I have had some problems with them working for me whereas HTML ones always work so far. So use the method that works for you, but do use inline citations.\n",
    "\n",
    "Here is an example of inline citation. After government genocide in the 20th century, real birds were replaced with surveillance drones designed to look just like birds<a name=\"lorenz\"></a>[<sup>[1]</sup>](#lorenznote). Use a minimum of 3 to 5 citations, but we prefer more <a name=\"admonish\"></a>[<sup>[2]</sup>](#admonishnote). You need enough citations to fully explain and back up important facts. \n",
    "\n",
    "Remeber you are trying to explain why someone would want to answer your question or why your hypothesis is in the form that you've stated. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement - Katie\n",
    "\n",
    "*Clearly describe the problem that you are solving. Avoid ambiguous words. The problem described should be well defined and should have at least one ML-relevant potential solution. Additionally, describe the problem thoroughly such that it is clear that the problem is quantifiable (the problem can be expressed in mathematical or logical terms), measurable (the problem can be measured by some metric and clearly observed), and replicable (the problem can be reproduced and occurs more than once).*\n",
    "\n",
    "Autonomous driving systems must make real-time decisions in dynamic environments while balancing safety, efficiency, and adherence to traffic rules. Traditional rule-based approaches struggle to generalize across diverse driving conditions, thus reinforcement learning (RL) is a promising alternative for self-driving applications. However, training RL models to drive safely and effectively remains a significant challenge due to the need for reliable evaluation metrics and the complexity of real-world driving scenarios.\n",
    "\n",
    "In this project, we aim to develop and compare reinforcement learning models for self-driving car simulations using CARLA. Our goal is to identify the model that achieves the highest overall performance across multiple key metrics, including:\n",
    "\n",
    "- Safety: Minimizing collisions with obstacles, pedestrians, and other vehicles\n",
    "- Lane Adherence: Ensuring the vehicle stays within lane boundaries and follows lane discipline\n",
    "- Traffic Rule Compliance: Obeying traffic lights, stop signs, and yielding rules\n",
    "- Efficiency: Reaching the intended destination within a reasonable time frame while maintaining safe driving behavior\n",
    "\n",
    "The vehicle's actions can be evaluated using numerical metrics such as collision count, lane deviation, and time to destination. Additionally, each episode in the CARLA simulation can be analyzed for performance using well-defined criteria. This is also replicable, as the experiment can be conducted multiple times with different RL models and configurations to assess their effectiveness under various driving conditions.\n",
    "\n",
    "Through this project, we seek to determine which RL algorithm and model architecture yield the best trade-off between safety, rule adherence, and efficiency, contributing to the broader field of autonomous vehicle research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data - Grace\n",
    "\n",
    "*You should have a strong idea of what dataset(s) will be used to accomplish this project.* \n",
    "\n",
    "*If you know what (some) of the data you will use, please give the following information for each dataset:*\n",
    "*- link/reference to obtain it*\n",
    "*- description of the size of the dataset (# of variables, # of observations)*\n",
    "*- what an observation consists of*\n",
    "*- what some critical variables are, how they are represented*\n",
    "*- any special handling, transformations, cleaning, etc will be needed*\n",
    "\n",
    "*If you don't yet know what your dataset(s) will be, you should describe what you desire in terms of the above bullets.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this is a reinforcement learning project, the agent will generate its own data through its interaction with the Webots environment and will not use a pre-existing static dataset. Each observation from the agent will consist of various sensor readings <a name=\"webots_sensors\"></a>[<sup>[2]</sup>](#webots_sensors_note):\n",
    "- **RGB image frames**: 1D byte array \n",
    "- **Point cloud distance data (LiDAR)**: 1D float array\n",
    "- **Proximity sensor data**: Float\n",
    "- **GPS coordinates**: 3D float array\n",
    "- **Acceleration**: 3D float array\n",
    "- **Angular velocity**: 3D float array\n",
    "- **Cardinal direction**: 3D float array\n",
    "- **Wheel rotation**: Float (in radians) \n",
    "- Control commands <a name=\"webots_carlib\"></a>[<sup>[3]</sup>](#webots_carlib_note)\n",
    "    - **Steering**: Float (in radians)\n",
    "    - **Throttle**: Float ([0, max_speed])\n",
    "    - **Braking**: Float ([0, 1])\n",
    "- **Time step**: Float\n",
    "\n",
    "To ensure the vehicle's safety, lane adherance, and traffic rule compliance the most critical variables are:\n",
    "- RGB image frames for detecting pedestrains, other vehicles, traffic signs/signals, and lanes\n",
    "- Point cloud distance data for determining following distance and preventing collisions\n",
    "- Proximity sensor data for accurate close range obstacle and collision detection\n",
    "\n",
    "To ensure the vehicle's efficiency the most critical variables are time step and GPS coordinates to minimize drive time verify the correct final destination. \n",
    "\n",
    "Webots by default runs at 32ms per time step, meaning approximately 31 observations will be recorded per 1 second of simulation time. Observations will be stored as NumPy arrays for optimal reinforcement learning training. To ensure consistency and prevent feature bias, the sensor data will be preprocessed. All sensor readings will be normalized to a common scale to improve stability and convergence speed. In addition, RGB images that are returned from as 1D arrays will be reshaped into 3D arrays (height x width x channels) and pixel values will be normalized. GPS coordinates will be converted from abosolute to relative positioning to simplify state representation. Lastly, null values returned by LiDAR sensors will be replaced with the maximum range of the sensor. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution - Hsiang-An\n",
    "\n",
    "The proposed solution combines **Reinforcement Learning (RL)** and **Convolutional Neural Networks (CNNs)** to develop a self-driving car system in a simulated environment created using **Webots**. The system learns to navigate autonomously by processing visual inputs from a front-facing camera and optimizing driving policies through trial and error.\n",
    "\n",
    "# **Model**\n",
    "- **Webots** provides a realistic simulation environment with customizable tracks and driving scenarios. The car is equipped with a front-facing camera to capture visual input, simulating real-world driving conditions.\n",
    "- A **CNN** processes raw image data to extract meaningful features (e.g., lane markings, obstacles, traffic signs).\n",
    "- Implemented using **PyTorch**, the CNN serves as the perception module, transforming visual inputs into a state space for the RL agent.\n",
    "- The RL agent may use **Proximal Policy Optimization (PPO)** to learn an optimal driving policy.\n",
    "- The state space consists of CNN-extracted features, and the action space includes controls like steering, throttle, and brake.\n",
    "- Includes reward fuctions that gives positive rewards for staying within lanes and maintaining safe speeds, negative rewards for collisions, going off-road, or violating traffic rules.\n",
    "\n",
    "# **Training Pipeline**\n",
    "1. The car collects image data from the Webots environment.\n",
    "2. The CNN processes the images and extracts features.\n",
    "3. The RL agent selects actions based on the features and receives rewards.\n",
    "4. The agent updates its policy iteratively using collected experiences.\n",
    "\n",
    "# **Testing and Evaluation**\n",
    "- The trained model is tested on unseen tracks or scenarios to evaluate generalization.\n",
    "- Evalutaion metrics are listed below \n",
    "- A **rule-based controller** serves as the **benchmark**. It follows predefined rules (e.g., stay in the center of the lane, stop at obstacles) without learning capabilities.\n",
    "\n",
    "---\n",
    "\n",
    "## Why This Solution Works\n",
    "\n",
    "- CNNs excel at processing image data and have been successfully used in autonomous driving tasks like lane detection and object recognition. By extracting meaningful features from raw images, the CNN enables the RL agent to interpret complex visual inputs effectively.\n",
    "- RL allows the agent to learn optimal policies through trial and error, making it well-suited for dynamic and unpredictable driving scenarios. The reward-based learning process ensures the agent improves over time by maximizing safe and efficient driving behaviors.\n",
    "- Webots provides a realistic and customizable environment for training and testing, enabling the simulation of diverse driving scenarios. The simulator's integration with PyTorch ensures a seamless and reproducible implementation.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics - Katie\n",
    "\n",
    "*Propose at least one evaluation metric that can be used to quantify the performance of both the benchmark model and the solution model. The evaluation metric(s) you propose should be appropriate given the context of the data, the problem statement, and the intended solution. Describe how the evaluation metric(s) are derived and provide an example of their mathematical representations (if applicable). Complex evaluation metrics should be clearly defined and quantifiable (can be expressed in mathematical or logical terms).*\n",
    "\n",
    "In this project, we evaluate the performance of both the **benchmark model** and the **solution model** using key safety and efficiency metrics. These metrics ensure that the self-driving agent follows safe driving behavior while effectively navigating to its destination.\n",
    "\n",
    "#### **1. Collision Rate (Safety)**\n",
    "**Definition:** Measures the frequency of collisions per episode.  \n",
    "- Lower values indicate better performance in avoiding obstacles and other vehicles.  \n",
    "- Derived from the number of collisions detected during the simulation.  \n",
    "\n",
    "**Mathematical Representation:**  \n",
    "$$\n",
    "\\text{Collision Rate} = \\frac{\\text{Total Collisions}}{\\text{Total Episodes}}\n",
    "$$\n",
    "Where:  \n",
    "- **Total Collisions** is the number of times the agent collides with an object\n",
    "- **Total Episodes** is the number of completed simulation runs\n",
    "\n",
    "**Example Interpretation:**  \n",
    "- If the agent crashes 10 times in 50 episodes, the collision rate is 0.2 (or 20%)  \n",
    "- A safer model should minimize this rate\n",
    "\n",
    "#### **2. Lane Adherence (Safety & Rule Compliance)**\n",
    "**Definition:** Measures how well the vehicle stays within lane boundaries  \n",
    "- Calculated as the deviation from the center of the assigned lane over time\n",
    "\n",
    "**Mathematical Representation:**  \n",
    "$$\n",
    "\\text{Lane Deviation} = \\frac{1}{T} \\sum_{t=1}^{T} |d_t|\n",
    "$$\n",
    "Where:  \n",
    "- \\( d_t \\) is the lateral distance from the lane center at time \\( t \\)\n",
    "- \\( T \\) is the total number of time steps in an episode\n",
    "\n",
    "**Example Interpretation:**  \n",
    "- A **higher deviation** means the vehicle frequently strays out of its lane\n",
    "- The goal is to **minimize lane deviation** for better lane-keeping performance\n",
    "\n",
    "#### **3. Traffic Rule Compliance (Safety & Legal Adherence)**\n",
    "**Definition:** Tracks the number of violations related to red lights, stop signs, and illegal lane changes\n",
    "- Lower values indicate better adherence to traffic laws\n",
    "\n",
    "**Mathematical Representation:**  \n",
    "$$\n",
    "\\text{Violation Rate} = \\frac{\\text{Total Violations}}{\\text{Total Episodes}}\n",
    "$$\n",
    "\n",
    "**Example Interpretation:**  \n",
    "- If a model runs 100 episodes and violates traffic rules 15 times, the violation rate is 0.15 (or 15%)\n",
    "- A safer model will have a near-zero violation rate\n",
    "\n",
    "#### **4. Time to Destination (Efficiency)**\n",
    "**Definition:** Measures the time taken to successfully reach the goal\n",
    "- A balance is needed: the car should not drive recklessly fast but also should not drive too slowly\n",
    "\n",
    "**Mathematical Representation:**  \n",
    "$$\n",
    "\\text{Time Efficiency} = \\frac{\\text{Total Distance Traveled}}{\\text{Total Time Taken}}\n",
    "$$\n",
    "\n",
    "**Example Interpretation:**  \n",
    "- If an agent takes 100 seconds to reach a 500m destination, its speed efficiency score is 5 m/s\n",
    "- A good model should balance speed while following safety rules\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy - Hsiang-An"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ethical concerns in this project are complex, with safety being a primary consideration. Self-driving vehicles rely on ML models to interpret their surroundings and make real-time decisions, but these models may encounter unpredictable scenarios that lead to accidents. Unlike human drivers, AI systems lack personal accountability, making it difficult to determine who is responsible when failures occur. Questions of liability (manufacturer, software engineers, or the vehicle owner) will become even more complicated if our model contributes to such issues. Another ethical dilemma arises in unavoidable accident scenarios, where the system may need to choose between different harmful outcomes. Should the vehicle prioritize the safety of its passengers over pedestrians or other drivers? This challenge highlights the difficulty engineers face in programming and defining ethical guidelines.\n",
    "\n",
    "Bias in machine learning models is another important consideration, as training data may not always represent the full diversity of real-world driving conditions. If the dataset lacks a wide range of pedestrian appearances or road environments, the AI may struggle to make fair and accurate decisions. Without comprehensive testing across diverse environments, the system could unintentionally discriminate against certain groups, leading to unsafe or unfair outcomes.\n",
    "\n",
    "Privacy is also a key concern, as self-driving vehicles collect vast amounts of data, including location, passenger behavior, to even personal/veicle information. We would make sure to include data that has been anonymized so that the data is essential for improving AI performance, but is not at risk of privacy leaks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Meet once a week via Zoom, more as needed closer to the end of the quarter\n",
    "* Respond in group chat within 12 hours\n",
    "* Conflict resolved by majority, any conflicts should be brought up within group before seeking TA assistance \n",
    "* Work should be divided evenly to the best of the group's ability\n",
    "* Be awafre of deadlines, each member's portion of work should be completed at least a couple hours prior to deadline to allow for revision \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal - Hsiang-An"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 2/12  |  5 PM |  Brainstorm topics/questions and split parts for research (all)  | Determine best form of communication; Discuss and decide on final project topic; discuss hypothesis; begin background research | \n",
    "| 2/14  |  12 PM |  Finalize Project Proposal (all), Search for datasets (Jiawei) | Complete background, Discuss datasets and metrics, finalize questions, Turn in proposal | \n",
    "| 2/21  | 5 PM  | Import and Wrangle Data (Hsiang-An), EDA (Grace)  | Discuss and finalize datasets and metrics for EDA, Review if work is divided in meaningful manner   |\n",
    "| 2/28  |  5 PM  | Finalize data, Continue on EDA (Grace), Programming start for RL (Katie) | Review if EDA and data wrangling is completed, Discuss possible algorithm, validations, model selection |\n",
    "| 3/5  | 6 PM  | Finalize EDA, continue programming (Katie), Start Analysis (Jiawei, Hsiang-An) | Review project code, Analyze algorithms and model performance, Split work based on what’s lacking |\n",
    "| 3/12  | 12 PM  | Complete Analysis ; Start results/conclusion/discussion (Grace, Katie)| Discuss and complete project, Plan for extra meeting if needed |\n",
    "| 3/16  | 5 PM  | Complete and Edit project (all)| Discuss and review report |\n",
    "| 3/19  | Before 11:59 PM  | Finalize project (all) | Turn in Final Project  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name=\"lorenznote\"></a>1.[^](#lorenz): Lorenz, T. (9 Dec 2021) Birds Aren’t Real, or Are They? Inside a Gen Z Conspiracy Theory. *The New York Times*. https://www.nytimes.com/2021/12/09/technology/birds-arent-real-gen-z-misinformation.html<br> \n",
    "<a name=\"webots_sensors_note\"></a>2.[^](#webots_sensors): Cyberbotics API Reference: doc. https://cyberbotics.com/doc/reference/nodes-and-api-functions?tab-language=python  \n",
    "<a name=\"webots_carlib_note\"></a>3.[^](#webots_carlib): Cyberbotics Car & Driver Library Reference: doc. https://cyberbotics.com/doc/automobile/car-and-driver-libraries \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11 (default, Jul 27 2021, 07:03:16) \n[Clang 10.0.0 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
